# -*- coding: utf-8 -*-
"""21112048_Denoising _Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rz2NMDXnssiacGoXUN_bdOgIpKpqY9Fd
"""

pip install opencv-python pillow numpy scikit-learn tensorflow torch torchvision

import os
import cv2
import numpy as np
import sklearn
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras import layers, models
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from skimage.metrics import peak_signal_noise_ratio as psnr

def load_images_from_folder(folder, img_size=(128, 128)):
    images = []
    for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        img = cv2.imread(img_path)
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB
            img = cv2.resize(img, img_size)  # Resize image
            img = img / 255.0  # Normalize to [0, 1]
            images.append(img)
    return images

noisy_folder_path = 'C:/Users/Gaurav Sharma/Desktop/Train/Train/low'
clean_folder_path = 'C:/Users/Gaurav Sharma/Desktop/Train/Train/high'
img_size = (128, 128)
noisy_images = load_images_from_folder(noisy_folder_path, img_size)
clean_images = load_images_from_folder(clean_folder_path, img_size)

train_noisy, train_noisy, train_clean, train_clean = train_test_split(
    noisy_images, clean_images, test_size=0.2, random_state=42
)

def preprocess_image(image):
    return tf.image.convert_image_dtype(image, tf.float32)

# Create TensorFlow datasets
train_noisy_ds = tf.data.Dataset.from_tensor_slices(train_noisy).map(preprocess_image).batch(32)
train_clean_ds = tf.data.Dataset.from_tensor_slices(train_clean).map(preprocess_image).batch(32)
test_noisy_ds = tf.data.Dataset.from_tensor_slices(test_noisy).map(preprocess_image).batch(32)
test_clean_ds = tf.data.Dataset.from_tensor_slices(test_clean).map(preprocess_image).batch(32)


train_ds = tf.data.Dataset.zip((train_noisy_ds, train_clean_ds))
test_ds = tf.data.Dataset.zip((test_noisy_ds, test_clean_ds))

import tensorflow as tf
from tensorflow.keras import layers, models, callbacks, Sequential
from tensorflow.keras.layers import LeakyReLU

# Define the PSNR function
def psnr(y_true, y_pred):
    max_pixel = 1.0
    return tf.image.psnr(y_true, y_pred, max_val=max_pixel)

# Define the custom PSNR callback
class PSNRCallback(callbacks.Callback):
    def __init__(self, validation_data):
        super().__init__()
        self.validation_data = validation_data

    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        val_data = self.validation_data
        val_pred = self.model.predict(val_data[0])
        logs['val_psnr'] = psnr(val_data[1], val_pred).numpy().mean()
        print(f"Epoch {epoch + 1}: val_psnr = {logs['val_psnr']}")

# Define the denoising model
def create_denoising_model(input_shape):
    model = Sequential()
    model.add(layers.Input(shape=input_shape))
    model.add(layers.Conv2D(64, (3, 3), activation=LeakyReLU(), padding='same'))
    model.add(layers.MaxPooling2D((2, 2), padding='same'))
    model.add(layers.Conv2D(32, (3, 3), activation=LeakyReLU(), padding='same'))
    model.add(layers.MaxPooling2D((2, 2), padding='same'))
    model.add(layers.Conv2D(32, (3, 3), activation=LeakyReLU(), padding='same'))
    model.add(layers.UpSampling2D((2, 2)))
    model.add(layers.Conv2D(64, (3, 3), activation=LeakyReLU(), padding='same'))
    model.add(layers.UpSampling2D((2, 2)))
    model.add(layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same'))
    return model


input_shape = (128, 128, 3)
model = create_denoising_model(input_shape)

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[psnr])
model.summary()


val_data = next(iter(test_ds))


psnr_callback = PSNRCallback(validation_data=val_data)

history = model.fit(train_ds, epochs=100, validation_data=test_ds, callbacks=[psnr_callback])

import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

predicted_images = model.predict(test_noisy_ds)

psnr_values = [psnr(test_clean[i], predicted_images[i]) for i in range(len(test_clean))]
average_psnr = np.mean(psnr_values)
print(f'Average PSNR: {average_psnr}')

predicted_images = model.predict(train_noisy_ds)

psnr_values = [psnr(train_clean[i], predicted_images[i]) for i in range(len(train_clean))]
average_psnr = np.mean(psnr_values)
print(f'Average PSNR: {average_psnr}')

import matplotlib.pyplot as plt
import numpy as np


def display_images(images, num_images_to_display=5):

    num_images = min(num_images_to_display, images.shape[0])


    fig, axes = plt.subplots(1, num_images, figsize=(15, 15))

    for i in range(num_images):
        ax = axes[i] if num_images > 1 else axes
        ax.imshow(images[i])
        ax.axis('off')

    plt.show()



display_images(predicted_images)

noisy_images = np.array(test_noisy)
display_images(noisy_images)

clean_images = np.array(test_clean)
display_images(clean_images)